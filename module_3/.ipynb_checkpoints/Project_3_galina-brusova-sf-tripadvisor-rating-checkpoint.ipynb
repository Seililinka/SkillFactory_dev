{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TripAdvisor_Rating [Brusova Galina]\n",
    "---\n",
    "\n",
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "import re\n",
    "import math\n",
    "import copy\n",
    "from IPython.display import display\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = '/kaggle/input/sf-dst-restaurant-rating/'\n",
    "path_to_file_2 = '/kaggle/input/new-city/'\n",
    "path_to_file_3 = '/kaggle/input/city-ch/'\n",
    "df_train = pd.read_csv(path_to_file+'main_task.csv')\n",
    "df_test = pd.read_csv(path_to_file+'kaggle_task.csv')\n",
    "cityn = pd.read_excel(path_to_file_2+'cityn.xls')\n",
    "city_ch = pd.read_excel(path_to_file_3+'city_ch.xls')\n",
    "pd.set_option('display.max_columns', 200)\n",
    "display(df_train.head(2))\n",
    "display(df_test.head(2))\n",
    "display(cityn.head(2))\n",
    "display(city_ch.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение колонок таблицы City (данные взяты с сайта https://www.numbeo.com/):\n",
    "* city - название города\n",
    "* sallary - Average Monthly Net Salary (After Tax)\n",
    "* ipoteka - Mortgage Interest Rate in Percentages (%), Yearly, for 20 Years Fixed-Rate\t\n",
    "* apart - Apartment (1 bedroom) in City Centre\n",
    "* transport - One-way Ticket (Local Transport)\n",
    "* milk_cost - Milk (regular), (1 liter)\n",
    "* exp_rest - cost Meal, Inexpensive Restaurant\n",
    "* mid_rest - Meal for 2 People, Mid-range Restaurant, Three-course\n",
    "* mcdac - McMeal at McDonalds (or Equivalent Combo Meal)\n",
    "* turizm - count of tourists\n",
    "\n",
    "Значение колонок таблицы City_ch (данные взяты с сайта https://www.numbeo.com/):\n",
    "* Crime - уровень преступности\n",
    "* Edu - уровень обоазования\n",
    "* Health - коэффициент уровня медицины "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "df_train['Sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['Sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\n",
    "df = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Детальный анализ по переменным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Обработаем даты отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Reviews = df.Reviews.apply(lambda string: np.nan if string == '[[], []]' else string)\n",
    "df[['g1', 'g2', 'g3', 'g4', 'g5']] = df.Reviews.str.split(\"[\", expand=True)\n",
    "del df['g1']\n",
    "del df['g2']\n",
    "del df['g5']\n",
    "del df['g3']\n",
    "df1 = df[['l1', 'l2', 'l3', 'l4', 'l5']] = df.g4.str.split(\"'\", expand=True)\n",
    "df1.columns = ['genres1', 'genres2', 'genres3', 'genres4', 'genres5']\n",
    "\n",
    "data['date1'] = df['l2']\n",
    "data['date2'] = df['l4']\n",
    "\n",
    "\n",
    "def change_max(column):\n",
    "    # присвоим значениям NaN самое частое значение\n",
    "    return data[column].fillna((data[column].value_counts().idxmax()), inplace=True)\n",
    "\n",
    "change_max('date1')\n",
    "change_max('date2')\n",
    "\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Найдем разницу между годами первого и второго отзыва"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['m1', 'd1', 'Y1']] = data.date1.str.split(\"/\", expand=True)\n",
    "data[['m2', 'd2', 'Y2']] = data.date2.str.split(\"/\", expand=True)\n",
    "for i in data['Y1']:\n",
    "    str(i).replace(' ', '')\n",
    "data['Y1'] = data['Y1'].replace(r'\\s+', '', regex=True)\n",
    "change_max('Y1') # заменим пустые значения Y1 на максимально встречающиеся \n",
    "change_max('Y2') # заменим пустые значения Y2 на максимально встречающиеся \n",
    "data['Y1'] = data['Y1'].astype(int) # изменим формат на int\n",
    "data['Y2'] = data['Y2'].astype(int) # изменим формат на int\n",
    "data['razn_Y'] = data['Y2']-data['Y1'] # найдем разницу между первым и вторым годом отзыва\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Добавим признак сетевого ресторана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## считаем, что если ID ресторана одинаковый, ресторан является сетевым\n",
    "chain_lst = list(data.Restaurant_id.value_counts()[data.Restaurant_id.value_counts() > 1].index)\n",
    "data['chain'] = data[data.Restaurant_id.isin(chain_lst)].Restaurant_id.apply(lambda x: 1)\n",
    "data['chain'].fillna(0, inplace=True)\n",
    "data['chain'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Добавим рейтинг городов (City_rate) по уровню жизни (данные wiki) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "cityk = pd.Series([41, 39, 46, 43, 13, 41, 56, 69, 37, 1, 11, 28, 19, 3, 40, 23, 76, 82, 33, 8, 89, 45, 2, 38, 9, 82, 25, 31, 80, 18, 74], index=['London', 'Paris', 'Madrid', 'Barcelona', 'Berlin', 'Milan', 'Rome', 'Prague', 'Lisbon', 'Vienna',\n",
    "'Amsterdam', 'Brussels', 'Hamburg', 'Munich', 'Lyon', 'Stockholm', 'Budapest', 'Warsaw', 'Dublin', 'Copenhagen', 'Athens', 'Edinburgh',\n",
    "'Zurich', 'Oporto', 'Geneva', 'Krakow', 'Oslo', 'Helsinki', 'Bratislava', 'Luxembourg', 'Ljubljana']).rename_axis('City')\n",
    "\n",
    "cityk= cityk.reset_index() # переиндексируем строки\n",
    "cityk.columns = ['City','city_rate'] # даем названия столбцам\n",
    "data = data.merge(cityk, on='City', how='left') # проводим merge с основной таблицей данных\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Добавим колонку суммы ресторанов по городам (City_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_count=df['City'].value_counts()\n",
    "rest_count = rest_count.reset_index() # переиндексируем строки\n",
    "rest_count.columns = ['City','City_count'] # дадим названия колонкам\n",
    "\n",
    "\n",
    "data = data.merge(rest_count, on='City', how='left') # проводим merge с основной таблицей данных\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Сделаем merge основной таблицы с таблицей Cityn и City_ch с данными по городам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(cityn, on='City', how='left')\n",
    "data = data.merge(city_ch, on='City', how='left')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Добавим признак (city_ranking) ranking с учетом количества ресторанов в городе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['city_ranking']=data['City_count']/data['Ranking']\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Заменим данные с нулевыми значениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_max(column):\n",
    "    # присвоим значениям NaN самое частое значение\n",
    "    return data[column].fillna((data[column].value_counts().idxmax()), inplace=True)\n",
    "\n",
    "def change_mode(column):\n",
    "    # присвоим значениям NaN значение моды\n",
    "    return df[column].fillna((int(df[column].mode())), inplace=True)\n",
    "\n",
    "change_max('Number of Reviews')\n",
    "change_max('Cuisine Style')\n",
    "change_max('Price Range')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Добавляем параметры по типам кухни и колонку (cuis_count) с количеством типов кухни в ресторане\n",
    "* CuisVeg - колонка наличия вегетарианской кухни\n",
    "* CuisBar - колонка наличия бара\n",
    "* CuisAsia - колонка наличия азиатской кухни\n",
    "* CuisEuro - колонка наличия европейской кухни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CuisCoint'] = data['Cuisine Style'].str.count(',') +1 # количество кухонь в ресторане\n",
    "data['CuisVeg'] = data['Cuisine Style'].str.count('Vegetarian Friendly' or 'Vegan')\n",
    "data['CuisBar'] = data['Cuisine Style'].str.count('Bar' or 'Pub')\n",
    "data['CuisAsia'] = data['Cuisine Style'].str.count('Asian' or 'Japanese')\n",
    "\n",
    "data['CuisEuro'] = data['Cuisine Style'].str.count('European')\n",
    "\n",
    "# попвытка проанализировать отзывы на предмет положительных слов дала ухудшение MAE.\n",
    "#data['Smile'] = data['Reviews'].str.count('Good') + data['Reviews'].str.count('Best') + data['Reviews'].str.count('Nice')+ data['Reviews'].str.count('Wonderful')+ data['Reviews'].str.count('Fine')+data['Reviews'].str.count('good') + data['Reviews'].str.count('best') + data['Reviews'].str.count('nice')+ data['Reviews'].str.count('wonderful')+ data['Reviews'].str.count('fine')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Заменим данные стоимости на числовые параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price Range'] = data['Price Range'].replace('$', 1)\n",
    "data['Price Range'] = data['Price Range'].replace('$$ - $$$', 2.5)\n",
    "data['Price Range'] = data['Price Range'].replace('$$$$', 4)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Добавим признак столицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_Of_NotCapitalCity = ['Barcelona', 'Milan', 'Hamburg', 'Munich', \n",
    "                          'Lyon', 'Zurich', 'Oporto', 'Geneva', 'Krakow']\n",
    "data['Capital_City'] = data['City'].apply(lambda x: 0.0 if x in list_Of_NotCapitalCity else 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Ranking нормализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Ranking']=data['Ranking']/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Посмотрим на данные в графическом виде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smth = data.hist(figsize=(20, 20), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasp(column):\n",
    "    # посмотрим распределение значений\n",
    "    return pd.DataFrame(data[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(rasp('CuisCoint'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(rasp('Number of Reviews'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data['Number of Reviews'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Построчная верификация первых двух строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Удалим не числовые столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['Restaurant_id', 'City', 'Cuisine Style', 'Price Range', 'Reviews', 'URL_TA', 'ID_TA', 'date_of_Review', 'len_date', 'Сountry', 'Сity_population', 'mean_Ranking_on_City', 'count_Restorant_in_City', 'max_Ranking_on_City', ], axis=1, inplace=True, errors='ignore')\n",
    "del data['City']\n",
    "del data['Cuisine Style']\n",
    "del data['Reviews']\n",
    "del data['URL_TA']\n",
    "del data['ID_TA']\n",
    "del data['date1']\n",
    "del data['date2']\n",
    "del data['m1'] \n",
    "del data['m2'] \n",
    "del data['d1'] \n",
    "del data['d2'] \n",
    "#del data['Y1'] \n",
    "#del data['Y2'] \n",
    "del data['Crime'] \n",
    "del data['HealthCare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разбиваем датасет на тренировочный и тестовый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.query('Sample == 1').drop(['Sample'], axis=1)\n",
    "test_data = data.query('Sample == 0').drop(['Sample'], axis=1)\n",
    "\n",
    "y = train_data.Rating.values            # наш таргет\n",
    "X = train_data.drop(['Restaurant_id', 'Rating'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n",
    "# выделим 20% данных на валидацию (параметр test_size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем\n",
    "test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем модель, генерируем результат и сравниваем с тестом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\n",
    "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель на тестовом наборе данных\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция стандартного математического округления\n",
    "def classic_round(d_num):\n",
    "    return int(d_num + (0.5 if d_num > 0 else -0.5))\n",
    "\n",
    "# функция округления кратно 0.5\n",
    "def my_round(d_pred):\n",
    "    result = classic_round(d_pred*2)/2\n",
    "    if result <=5:\n",
    "        return result\n",
    "    else:\n",
    "        return 5\n",
    "    \n",
    "# создание функции для векторов np\n",
    "my_vec_round = np.vectorize(my_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = my_vec_round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "MAE = metrics.mean_absolute_error(y_test, y_pred)\n",
    "print('MAE:', MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\n",
    "plt.rcParams['figure.figsize'] = (12,10)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверяем корреляцию важных переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = data.loc[df['Sample'] == 1, list(feat_importances.nlargest(15).index[0:15])]\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "ax = sns.heatmap(df_temp.corr(), annot=True, fmt='.2g')\n",
    "i, k = ax.get_ylim()\n",
    "ax.set_ylim(i+0.5, k-0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно проследить несколько зависмсостей: \n",
    "1. Чем выше зарпалата в городе, тем выше ипотека\n",
    "2. Чем больше количество отзывов, тем ниже оценка и большее количество видов кухни в ресторане.\n",
    "3. Цена за апартаменты выше, чем более туристический город. Туризм также сильно влияет на Ranking.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_temp = list(feat_importances.nlargest(15).index[[9,10]])\n",
    "display(df_temp[list_temp].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_temp = list(feat_importances.nlargest(15).index[[0,1,6,10]])\n",
    "df_temp[list_temp].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(path_to_file+'sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Готовим submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['Rating','Restaurant_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# приведем к кратности шага 0.5\n",
    "predict_submission = list(map(lambda x: round(x * 2)/2, predict_submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['Rating'] = predict_submission\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
